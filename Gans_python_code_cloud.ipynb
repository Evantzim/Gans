{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e292e39b-d368-45ef-aacf-4c80a824fef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: pymysql in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: requests in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\evangelos\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "!pip install pymysql\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2869dcd-eb3a-49bc-b81a-7a965689129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7134a92b-5aab-4fc6-9666-b1885e6ba6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_with_sql():\n",
    "    schema = \"cities_info\"\n",
    "    host = \"host_id\"\n",
    "    user = \"root\"\n",
    "    password = \"Password\"\n",
    "    port = 3306\n",
    "\n",
    "    connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "    return connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37b724d7-3676-4a0f-911b-540d5975fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cities_data(NewcityEntry):\n",
    "    cities_ration=[]\n",
    "    for i in NewcityEntry:\n",
    "        url = \"https://en.wikipedia.org/wiki/\"+i\n",
    "        response = requests.get(url)\n",
    "        cities_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        city_ration={\n",
    "            \"City\" : i,\n",
    "            \"Country\" : cities_soup.find(string=re.compile(\"Country\")).find_next(\"td\").get_text(),\n",
    "            \"Latitude\" : cities_soup.find(class_=\"latitude\").get_text(),\n",
    "            \"Longitude\" : cities_soup.find(class_=\"longitude\").get_text()}\n",
    "        cities_ration.append(city_ration)\n",
    "    cities_first_df= pd.DataFrame(cities_ration)\n",
    "    cities_first_df.to_sql('cities',\n",
    "                  if_exists='append',\n",
    "                  con=connection_with_sql(),\n",
    "                  index=False)\n",
    "    return pd.DataFrame(cities_ration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53b77615-0c28-4680-94da-aabc95a2c239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Munich</td>\n",
       "      <td>Germany</td>\n",
       "      <td>48°08′15″N</td>\n",
       "      <td>11°34′30″E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Germany</td>\n",
       "      <td>53°33′N</td>\n",
       "      <td>10°00′E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "      <td>52°31′12″N</td>\n",
       "      <td>13°24′18″E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City  Country    Latitude   Longitude\n",
       "0   Munich  Germany  48°08′15″N  11°34′30″E\n",
       "1  Hamburg  Germany     53°33′N     10°00′E\n",
       "2   Berlin  Germany  52°31′12″N  13°24′18″E"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_final = cities_data(NewcityEntry=[\"Munich\", \"Hamburg\", \"Berlin\"])\n",
    "cities_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c811c1-e0df-4d3c-b32b-beb8cc8dd46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db136e4e-e8c4-4f0b-b949-61ae266cdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cities_population():\n",
    "    cities_from_sql = pd.read_sql(\"cities\", con=connection_with_sql())\n",
    "    cities_pop=[]\n",
    "    for i in cities_from_sql[\"City\"]:\n",
    "        url = \"https://en.wikipedia.org/wiki/\"+i\n",
    "        response = requests.get(url)\n",
    "        cities_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pop = cities_soup.find(string=(\"Population\")).find_next(\"td\").get_text()\n",
    "        pop_int = int(pop.replace(\",\",\"\"))\n",
    "        city_pop={\n",
    "            \"City\" : i,\n",
    "            \"Population\" : pop_int,\n",
    "            \"Year_Data_Retrieved\" : dt.datetime.now().strftime('%Y-%m-%d')\n",
    "        }\n",
    "        cities_pop.append(city_pop)\n",
    "    cities_pop_df= pd.DataFrame(cities_pop)\n",
    "    cities_id_pop_df = cities_pop_df.merge(cities_from_sql,\n",
    "                                           on = \"City\",\n",
    "                                           how=\"left\")[[\"city_id\",\"Population\",\"Year_Data_Retrieved\"]]\n",
    "    cities_id_pop_df.to_sql('population',\n",
    "                            if_exists='append',\n",
    "                            con=connection_with_sql(),\n",
    "                            index=False)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6c8c0ce-087f-4696-8a51-1e60fefdc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b734790-29b4-4523-acef-726dc749901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cities_weather():\n",
    "    cities_from_sql = pd.read_sql(\"cities\", con=connection_with_sql())\n",
    "# Create an empty list which will be filled with the average temp, main weather, description of weather and  time.\n",
    "    forecasts_data = []\n",
    "    for i, row in cities_from_sql.iterrows():\n",
    "        city_name_forec = row[\"City\"]\n",
    "        API_key = \"weather_API\"\n",
    "        weather_5_day_per_city= requests.get(f\"https://api.openweathermap.org/data/2.5/forecast?q={city_name_forec}&units=metric&&appid={API_key}\")\n",
    "        weather_5_day_per_city = weather_5_day_per_city.json()\n",
    "\n",
    "# Create an empty list which will be filled with the average temp, main weather, description of weather and  time.\n",
    "\n",
    "# Loop through the forecasts\n",
    "        for forecast in weather_5_day_per_city[\"list\"]:\n",
    "            forecasts_dict = { \n",
    "                \"City\" : city_name_forec,\n",
    "                \"Avg_temperature\"     : forecast[\"main\"][\"temp\"],\n",
    "                \"Max_temperature\"     : forecast[\"main\"][\"temp_max\"],\n",
    "                \"Min_temperature\"     : forecast[\"main\"][\"temp_min\"],\n",
    "                \"Weather_prediction\"  : forecast[\"weather\"][0][\"main\"],\n",
    "                \"Weather_description\" : forecast[\"weather\"][0][\"description\"],\n",
    "                \"Forecast_time\"       : forecast[\"dt_txt\"],\n",
    "                \"Timestamp_retrieved\" : dt.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            }\n",
    "            forecasts_data.append(forecasts_dict)\n",
    "        forecasts_df = pd.DataFrame(forecasts_data)   \n",
    "        cities_forecast_df = forecasts_df.merge(cities_from_sql,\n",
    "                                                 on = \"City\",\n",
    "                                                 how=\"left\")[[\"city_id\",\n",
    "                                                         \"Avg_temperature\",\n",
    "                                                         \"Max_temperature\",\n",
    "                                                         \"Min_temperature\",\n",
    "                                                         \"Weather_prediction\",\n",
    "                                                         \"Weather_description\",\n",
    "                                                         \"Forecast_time\",\n",
    "                                                         \"Timestamp_retrieved\"]]\n",
    "        cities_forecast_df.to_sql('weather_data_5days',\n",
    "                             if_exists='append',\n",
    "                             con=connection_with_sql(),\n",
    "                             index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7acc708f-e877-41ee-bbab-37878b406945",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b3f7626-d500-41bc-ace3-eb8297dc1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_coord(coordinate):\n",
    "\n",
    "    degrees = coordinate[:2]\n",
    "    decimal_degrees = float(coordinate[3:5])/60\n",
    "    total_degrees = int(degrees) + float(decimal_degrees)\n",
    "    direction = 1\n",
    "    if coordinate[-1] in (\"S\" or \"W\"):\n",
    "        direction = -1\n",
    "    form_coord = round(total_degrees * direction, 5)\n",
    "    return form_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d93e6b0-79a8-4e36-b5d2-c0a9e16c29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cities_airports():\n",
    "    cities_from_sql = pd.read_sql(\"cities\", con=connection_with_sql())\n",
    "    airports_list = []\n",
    "    airports_cities_list = []\n",
    "    for i, row in cities_from_sql.iterrows():\n",
    "        \n",
    "        lat = decimal_coord(row[\"Latitude\"])\n",
    "        long = decimal_coord(row[\"Longitude\"])\n",
    "\n",
    "        url = f\"https://aerodatabox.p.rapidapi.com/airports/search/location/{lat}/{long}/km/50/16\"\n",
    "\n",
    "        querystring = {\"withFlightInfoOnly\":\"true\"}\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\",\n",
    "            \"X-RapidAPI-Key\": \"flight_API\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=querystring)\n",
    "        airports_data = response.json()\n",
    "        \n",
    "        \n",
    "        for data in airports_data[\"items\"]:\n",
    "            airport_list = {\n",
    "                \"icao\" : data[\"icao\"],\n",
    "                \"airport_iata\" : data[\"iata\"],\n",
    "                \"Airport_name\" : data[\"name\"],\n",
    "                \"Airport_name_short\" : data[\"shortName\"],\n",
    "                \"Country_Code\" : data[\"countryCode\"],\n",
    "                \"Timezone\" : data[\"timeZone\"],\n",
    "                \"Municipality\" : data[\"municipalityName\"]\n",
    "            }\n",
    "            airports_list.append(airport_list)\n",
    "            airport_city_list = {\n",
    "                \"airport_iata\" : data[\"iata\"],\n",
    "                \"city_id\" : row[\"city_id\"]\n",
    "            }\n",
    "            airports_cities_list.append(airport_city_list)\n",
    "    airports_df = pd.DataFrame(airports_list)\n",
    "    airports_df.drop_duplicates(inplace=True)\n",
    "    airports_cities_df = pd.DataFrame(airports_cities_list)\n",
    "\n",
    "\n",
    "    airports_df.to_sql('airports',\n",
    "                       if_exists='append',\n",
    "                       con=connection_with_sql(),\n",
    "                       index=False)\n",
    "    airports_cities_df.to_sql('cities_airports',\n",
    "                       if_exists='append',\n",
    "                       con=connection_with_sql(),\n",
    "                       index=False)\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dfe96e8-62b3-4267-b74e-dc1172126c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_airports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da6cdc5b-0aff-4050-8a81-e244f39b0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flights_info():\n",
    "    airports_from_sql = pd.read_sql(\"airports\", con=connection_with_sql())\n",
    "\n",
    "    # Get today date\n",
    "    today = dt.date.today()\n",
    "    # Get tomorrow date\n",
    "    tomorrow = today + dt.timedelta(days=1)\n",
    "    # Get tomorrow date in string type\n",
    "    tomorrow_str = dt.date.isoformat(tomorrow)\n",
    "    tomorrow_first_part_begin = f\"{tomorrow_str}T00:00\"\n",
    "    tomorrow_first_part_end = f\"{tomorrow_str}T11:59\"\n",
    "    tomorrow_second_part_begin = f\"{tomorrow_str}T12:00\"\n",
    "    tomorrow_second_part_end = f\"{tomorrow_str}T23:59\"\n",
    "    tomorrow_dict = [(tomorrow_first_part_begin,tomorrow_first_part_end),(tomorrow_second_part_begin,tomorrow_second_part_end)]\n",
    "    flights_data = []\n",
    "    for tomorrow_part1,tomorrow_part2 in tomorrow_dict:\n",
    "        \n",
    "        for i, row in airports_from_sql.iterrows():\n",
    "            url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/iata/{row[\"airport_iata\"]}/{tomorrow_part1}/{tomorrow_part2}\"\n",
    "\n",
    "            querystring = {\"withLeg\":\"true\",\"direction\":\"Arrival\",\"withCancelled\":\"false\",\"withCodeshared\":\"false\",\"withCargo\":\"false\",\"withPrivate\":\"false\",\"withLocation\":\"false\"}\n",
    "\n",
    "            headers = {\n",
    "                \"x-rapidapi-key\": \"FLIGHTapi\",\n",
    "                \"x-rapidapi-host\": \"aerodatabox.p.rapidapi.com\"\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, headers=headers, params=querystring)\n",
    "            flights = response.json()\n",
    "        \n",
    "            \n",
    "            for flight in flights[\"arrivals\"]:\n",
    "\n",
    "                flight_data = {\n",
    "                    \"Arrival_time\" : flight[\"arrival\"][\"scheduledTime\"][\"utc\"],\n",
    "                    \"airport_iata\" : row[\"airport_iata\"],\n",
    "                    \"Revised_time\" : flight[\"arrival\"].get(\"revisedTime\",{\"utc\":flight[\"arrival\"][\"scheduledTime\"][\"utc\"]})[\"utc\"],\n",
    "                    \"Departure_city\" : flight[\"departure\"][\"airport\"][\"name\"],\n",
    "                    \"Terminal\" : flight[\"number\"]\n",
    "                }\n",
    "                flights_data.append(flight_data)\n",
    "            flight_data_df =pd.DataFrame(flights_data)\n",
    "    flight_data_df.to_sql('flights',\n",
    "                      if_exists='append',\n",
    "                      con=connection_with_sql(),\n",
    "                      index=False)        \n",
    "    return  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fee985a8-a154-49fa-91a7-73fdc95d83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
